{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Pipeline that starts an inferencing service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from string import Template\n",
    "\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.dsl.types import Float, String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"deploy_pipeline\",\n",
    "    description=\"\"\"A pipeline that starts a serverless inferencing service.\"\"\",\n",
    ")\n",
    "def deploy(\n",
    "    model_version: String = \"\",\n",
    "    subdomain: String = \"\"\n",
    "):\n",
    "    jsontemplate = Template(\"\"\"\n",
    "    {\n",
    "      \"apiVersion\": \"serving.kubeflow.org/v1alpha2\",\n",
    "      \"kind\": \"InferenceService\",\n",
    "      \"metadata\": {\n",
    "        \"name\": \"$subdomain\",\n",
    "        \"namespace\": \"anonymous\"\n",
    "      },\n",
    "      \"spec\": {\n",
    "        \"default\": {\n",
    "          \"predictor\": {\n",
    "            \"serviceAccountName\": \"sa\",\n",
    "            \"pytorch\": {\n",
    "              \"storageUri\": \"s3://mlpipeline/$model_version/\",\n",
    "              \"modelClassName\": \"Net\",\n",
    "              \"resources\": {\n",
    "                \"limits\": {\n",
    "                  \"cpu\": \"4.0\",\n",
    "                  \"memory\": \"2Gi\"\n",
    "                },\n",
    "                \"requests\": {\n",
    "                  \"cpu\": \"0.1\",\n",
    "                  \"memory\": \"1Gi\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \"\"\")\n",
    "    inference_service = jsontemplate.substitute({\n",
    "      \"model_version\": model_version,\n",
    "      \"subdomain\": subdomain\n",
    "    })\n",
    "    deployment = json.loads(inference_service)\n",
    "    serve_op = dsl.ResourceOp(\n",
    "        name=\"deploy\",\n",
    "        k8s_resource=deployment,\n",
    "        success_condition=\"status.conditions.0.status == True\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(deploy, \"deployment.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<a href=\"/notebook/anonymous/my-notebook-server/files/kubeflow-aiops-workshop/notebooks/deployment.zip?download=1\">Download</a>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
